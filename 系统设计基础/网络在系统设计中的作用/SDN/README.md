<!--
 * @Author: shgopher shgopher@gmail.com
 * @Date: 2024-09-15 17:04:57
 * @LastEditors: shgopher shgopher@gmail.com
 * @LastEditTime: 2024-10-15 13:48:05
 * @FilePath: /luban/系统设计基础/网络在系统设计中的作用/SDN/README.md
 * @Description: 
 * 
 * Copyright (c) 2024 by shgopher, All Rights Reserved. 
-->
# sdn
(sdn software defined network) 软件定义网络，它将网络控制平面和数据层面分离，这里面有一个重要的技术 lvs 它就是三层负载均衡，二层负载均衡的运用。

**其核心技术就是 LVS**
## lvs 基本原理
通过修改七层网络中的数据链路层的 mac 协议，网络层的 ip 协议，实现了交换机 (处理 mac 协议) 网关 (处理 ip 协议) 的数据包转发。从而将数据转发到真正的服务器上。

lvs 有四种模式

- NAT 模式 (三层负载均衡)
- FULL-NAT 模式 (三层负载均衡)
- TUN 模式 (二层负载均衡，部分三层负载均衡)
- DR 模式 (二层负载均衡)

只有仅有二层负载均衡的就只能用在内网中，因为没有 ip 识别是无法在公网中使用的。

只有涉及到了三层负载均衡，就能用在公网中，所以显而易见的，DR 模式最底层，性能最高，但是只能用在内网中
### NAT 模式
![nat](./nat.svg)
### FULLNAT 模式
![fullNat](./full-nat.svg)
### TUN 模式
由于第三层的数据包，即 IP 数据包中包含了源 (客户端) 和目标 (均衡器) 的 IP 地址，只有真实服务器保证自己的 IP 地址与数据包中的目标 IP 地址一致，这个数据包才能被正确处理。因此，使用这种负载均衡模式时，需要把真实物理服务器集群所有机器的虚拟 IP 地址 (Virtual IP Address，VIP) 配置成与负载均衡器的虚拟 IP 一样，这样经均衡器转发后的数据包就能在真实服务器中顺利地使用

![tun](./tun.svg)
### DR 模式
![dr](./dr.svg)
由于需要更改目标 mac 地址，这就意味着该负载均衡器必须与真实的服务在 mac 层能建立通信，所以这就意味着它只能运行在内网中
### 四种模式对比
|模式|优势|劣势|
|:---:|:---:|:---:|
|NAT|不需要配置虚拟 ip，可以跨网|流量必须双向流经 lvs，性能较差|
|FULL-NAT|不需要配置虚拟 ip，可以跨网|丢失客户端 ip，流量必须双向流经 lvs，性能较差|
|TUN|性能高|必须支持 ip 隧穿的功能，必须配置和 lvs 公网一致的虚拟 ip|
|DAR|性能最高|仅支持内网通信，并且必须配置和 lvs 公网一致的虚拟 ip|
## 虚拟 ip 的虚拟性质
高可用性：VIP 的存在使得后端真实服务器对于客户端来说是一个统一的服务入口。即使某一个 LVS 服务器出现故障，客户端仍然可以通过 VIP 访问到服务，因为 VIP 可以动态地在不同的 LVS 服务器之间转移。这种灵活性和高可用性是与普通网卡 IP 不同的，普通网卡 IP 如果对应的网卡或主机出现故障，该 IP 就无法正常提供服务了。

负载均衡：VIP 作为前端的统一入口，LVS 服务器可以根据不同的负载均衡算法 (如轮询、加权轮询、最小连接数等) 将客户端请求分配到后端不同的真实服务器上。这就像一个虚拟的服务端点，隐藏了后端真实服务器的 IP 地址和复杂的网络拓扑结构，更像是一个抽象的、虚拟的服务 IP，而非单纯的一个网卡 IP
## keepalived
Keepalived 是一款基于 VRRP (Virtual Router Redundancy Protocol，虚拟路由器冗余协议) 实现的高可用性 (HA) 软件。它主要用于服务器的负载均衡和高可用性场景，能够确保在服务器出现故障或网络异常时，服务仍能持续、稳定地提供。

从网络外部看来，VIP 就像是一个独立的、可供访问的 IP 地址，但实际上这个 VIP 可以在多个 LVS 服务器之间灵活切换。在正常情况下，这个 VIP 可能被 “绑定” 在主 LVS 服务器的网卡上，对外提供服务。但这并不是传统意义上的网卡自身的固定 IP，因为当主服务器出现故障时，通过 VRRP 机制，这个 VIP 会迅速地被绑定到备用 LVS 服务器的网卡上。

它的基本原理是：
- 两台机器配置同一个 vip (虚拟 ip)
- 两台 lvs 系统通过 keepalived 频繁通信，评估哪个机器分数高，高的那个作为 master，另一台作为备份，得分高的通过 vrrp 组播报文宣称 vip 在这里
- 如果 master 宕机了，备份机器会立刻宣称 vip 在自己这里

在没有发生故障转移时，备用 LVS 设备通常不会绑定和主设备相同的虚拟 IP (VIP)

在正常情况下，主 LVS 设备会响应 VRRP 通告，从而拥有 VIP 的所有权。此时，从网络层面看，VIP 是绑定在主 LVS 设备的网络接口上的，外部网络流量根据这个 VIP 指向主 LVS 设备。

备用 LVS 设备处于监听状态，它会接收主 LVS 设备发送的 VRRP 通告，以确认主设备的存活状态。**它自身并没有绑定这个 VIP，因为如果同时绑定，可能会导致 IP 地址冲突和网络混乱，比如出现流量被不恰当的分流到备用设备或者产生路由环路等问题。**

这里的虚拟 ip 实际上就是一个公网 ip。

> 作为最前面的网关，防火墙作为网关，其公网接口同样具有真实 IP 地址
## 更多优化方法
- dpdk，因为 lvs 基于 Linux 内核的 netilter，需要内核态和用户态切换，因此 dpdk，通过申请大内存，以及轮询替代中断，完成更高性能的表现，[dpvs](https://github.com/iqiyi/dpvs) 是 dpdk 技术的开源项目
## 使用 lvs +  nginx (或者 kong) 的实战部署
首先，为了提高可用性，我们都会采用集群的方式去部署 lvs 和 nginx，我们通常使用主-从的方式去部署高可用的 lvs 集群的方案。


## 一个更加高性能的物理路由 + 物理交换机 + lvs + nginx(kong) 的实战部署
这种更加高性能的场景也遵循上文提到的高可用主从备份的方案。

