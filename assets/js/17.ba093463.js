(window.webpackJsonp=window.webpackJsonp||[]).push([[17],{441:function(v,_,t){v.exports=t.p+"assets/img/hash1.7380af14.svg"},536:function(v,_,t){"use strict";t.r(_);var s=t(36),p=Object(s.a)({},(function(){var v=this,_=v.$createElement,s=v._self._c||_;return s("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[s("h1",{attrs:{id:"一致性哈希分片算法"}},[v._v("一致性哈希分片算法")]),v._v(" "),s("p",[v._v("我们知道 Raft 算法中，写只能存在于领导节点，导致整个集群的接入性能基本上等于单机，随着业务的发展我们需要使用分片的技术，一致性哈希分片算法就是分片算法中的佼佼者。")]),v._v(" "),s("p",[v._v("普通的哈希算法不也行吗，加一个 proxy 层然后将不同规则的访问导向不同的片区，当然，如果不涉及到数据的迁移当然是可以的，但是如果涉及到数据的迁移，普通的哈希算法就会出现问题，重新映射的花销水非常的大的，所以我们要使用一致性哈希")]),v._v(" "),s("p",[v._v("普通的哈希算法如何获得具体的节点值呢？")]),v._v(" "),s("p",[s("code",[v._v("hash(key)%3")])]),v._v(" "),s("p",[v._v("访问的数据 key 值，计算的节点跟节点总数取余数即可获取一个小于等于 3 的值，那么这个值就是导向的节点值。")]),v._v(" "),s("p",[v._v("那么一致性哈希呢？")]),v._v(" "),s("p",[s("strong",[v._v("一致性哈希将对节点总数取余数改成了对 2 ^ 32 取余数")])]),v._v(" "),s("p",[v._v("一致性哈希算法将整个哈希空间想象成一个虚拟的圆环，哈希环")]),v._v(" "),s("p",[s("code",[v._v("hash(key) % （2^32）")]),v._v(" 算出来结果之后，就会碰到节点的标号，节点标号刚好在 [0,2^32)之间，就像下面这样的")]),v._v(" "),s("p",[s("img",{attrs:{src:t(441),alt:"hash1"}})]),v._v(" "),s("p",[v._v("当某个节点宕机，比如 A 宕机，那么 A 前面的数据可以顺延到 B 节点即可，扩容也一样，反正向后寻址即可。")]),v._v(" "),s("p",[v._v("为了防止节点分配的不均匀，我们可以设置虚拟节点，比如节点 A 非常的强大，那么我们可以将它设置为 A1 A2 A3 然后混合其它节点均匀的分布在整个环上。")]),v._v(" "),s("p",[v._v("为了让服务器节点分配的比较均匀，我们可以对服务器本身进行哈希取值，尽量的让它分布的比较均匀。")]),v._v(" "),s("h2",{attrs:{id:"如何进行数据的迁移"}},[v._v("如何进行数据的迁移")]),v._v(" "),s("ul",[s("li",[s("p",[v._v("定期备份策略。系统通常会按照一定的时间间隔 (比如每隔一小时、一天等，具体根据业务数据变更频率来定) 对各个节点上的数据进行备份，备份数据可以存储在独立的存储介质 (如专门的备份服务器、磁带库等) 中，例如，一个分布式存储系统，每天凌晨 2 点会对所有节点数据全量备份，中午某个节点宕机了，那可以拿凌晨备份的数据来按规则向其他节点迁移恢复")])]),v._v(" "),s("li",[s("p",[v._v("多副本冗余机制。数据会同时存储在多个不同的节点上，当其中一个节点宕机，剩余的正常节点上的副本依然可用，把原本宕机节点上那部分副本职责合理分摊到其他未宕机的节点上，完成类似数据迁移的效果。")])])])])}),[],!1,null,null,null);_.default=p.exports}}]);